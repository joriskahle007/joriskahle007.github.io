---
layout: post
title: Grundwissen: GPT, Token, PTUs & Prompts â€“ was Du verstehen solltest, bevor Du loslegst
tags: [AI, Voraussetzungen]
---

Bevor Du Dich in Azure AI Foundry, Azure OpenAI oder generell in generative KI stÃ¼rzt, ist es hilfreich, wenn Du ein paar grundlegende Begriffe verstehst. Viele davon begegnen Dir stÃ¤ndig â€“ z.â€¯B. in der Kostenberechnung oder beim Umgang mit Modellen wie GPT-4.

Hier kommt Dein Mini-Crashkurs. ğŸ‘‡

## Was ist GPT Ã¼berhaupt?
**GPT** steht fÃ¼r **Generative Pre-trained Transformer**. Es ist ein Sprachmodell, das:

- mit riesigen Mengen an Text vortrainiert wurde
- Sprache versteht und erzeugt (Text, Code, E-Mails, Zusammenfassungen etc.)
- mit sog. *Prompts* gesteuert wird â€“ also Texteingaben, mit denen Du dem Modell sagst, was es tun soll

Modelle wie *GPT-4*, *GPT-3.5*, oder *GPT-4 Turbo* sind Varianten dieses Prinzips â€“ jede Version ist leistungsfÃ¤higer, schneller oder gÃ¼nstiger.

## Was ist ein Prompt?
Ein **Prompt** ist einfach gesagt **Dein Befehl an das Modell.**

Beispiele fÃ¼r Prompts:
- â€Fasse diesen Text in drei SÃ¤tzen zusammen.â€œ
- â€Schreibe eine Einladung fÃ¼r ein Sommerfest.â€œ
- â€Welche Risiken birgt generative KI in der Medizin?â€œ

Je besser Dein Prompt, desto prÃ¤ziser die Antwort â€“ das nennt man auch **Prompt Engineering.**

## Was sind Tokens und warum sind sie wichtig?
Ein **Token** ist ein Teil eines Wortes â€“ nicht immer ein ganzes Wort!
Token ist aber nicht gleich Toiken

| Beispiel | Wort | Token(s) |
| â€Computerâ€œ |	1 Wort |	1 Token |
| â€Unvorstellbarâ€œ |	1 Wort |	2 Tokens (â€Un-â€œ, â€vorstellbarâ€œ) |
| â€Hello, world!â€œ |	2 WÃ¶rter |	4 Tokens (Hello, ,, space, world!) |

Tokens sind deshalb wichtig, weil GPT-Modelle nach Tokens abgerechnet werden â€“ nicht nach WÃ¶rtern oder Prompts.

Beispiel:

- Du schreibst eine Eingabe mit 100 Tokens.
- GPT erzeugt eine Antwort mit 300 Tokens.
- Abgerechnet werden also 400 Tokens.

## Wie funktioniert die Abrechnung in Azure OpenAI?
Wenn Du GPT Ã¼ber **Azure OpenAI** nutzt (auch Ã¼ber Foundry eingebunden), hast Du diese Abrechnungsgrundlagen:

## Kosten nach Modell und Tokens
Du zahlst pro **1.000 Tokens**, abhÃ¤ngig vom Modell:

| Modell |	Prompt (Input) |	Completion (Output) |	Beispiel |
| GPT-4 Turbo |	ca. $0.01	| ca. $0.03	| pro 1.000 Tokens |
| GPT-3.5	| gÃ¼nstiger	| gÃ¼nstiger	| < $0.001 pro 1.000 Tokens |

Die **Preise kÃ¶nnen sich Ã¤ndern**, darum lohnt sich ein Blick auf <a https://azure.microsoft.com/de-de/pricing/details/cognitive-services/openai-service/>Microsofts Preisseite fÃ¼r Azure OpenAI</a>.

## Was bedeutet Tokens per Minute (TPM)?
In Azure hast Du zusÃ¤tzlich **Rate Limits:**

- **Tokens per Minute (TPM)**: Wie viele Tokens Du pro Minute senden darfst.
- **Requests per Minute (RPM)**: Wie viele Anfragen Du pro Minute stellen darfst.

Wenn Du z.â€¯B. 240.000 TPM hast, kannst Du:

- 6 Anfragen mit je 40.000 Tokens
- oder 24 Anfragen mit je 10.000 Tokens
- â€¦ pro Minute senden

Diese Limits skalieren je nach deinem **Nutzungskontingent**, und Du kannst bei Microsoft **erhÃ¶hte Quoten beantragen**, wenn Du mehr brauchst.

## Was ist eine Provisioned Throughput Unit (PTU)?
Eine **PTU** ist eine **Abrechnungseinheit in Azure OpenAI**, die Dir eine bestimmte Menge an RechenkapazitÃ¤t fÃ¼r GPT-Modelle zusichert â€“ Ã¤hnlich wie bei einer reservierten Bandbreite.

**Eine PTU bestimmt:**
- Wie viele **Token pro Minute (TPM)** Du verarbeiten kannst
- Welche **Modelle** (GPT-3.5, GPT-4, GPT-4 Turbo etc.) Du wie performant ansprechen kannst
- Wie hoch **verfÃ¼gbar** Deine Ressourcen sind

## Was bekommst Du pro PTU?
Microsoft gibt typischerweise an:

- z.â€¯B. **1 PTU GPT-4 Turbo** = ~20 Requests/Minute mit je 8.000 Tokens (konkrete Werte kÃ¶nnen variieren)
- PTUs gelten **modellabhÃ¤ngig** â€“ d.â€¯h. GPT-3.5 hat gÃ¼nstigere, kleinere PTUs als GPT-4 Turbo
- Du kannst **mehrere PTUs buchen**, um KapazitÃ¤t zu skalieren

Diese PTUs gelten **pro Region und Deployment**, also z.â€¯B. â€West Europe â€“ GPT-4 Turbo â€“ 2 PTUsâ€œ.

## Warum gibt es PTUs Ã¼berhaupt?
Microsoft bietet mit PTUs:

- **Planbare Leistung** â€“ Du bekommst zugesicherte KapazitÃ¤t, unabhÃ¤ngig von Auslastung
- **VerlÃ¤ssliche API-Nutzung** â€“ wichtig fÃ¼r produktive Anwendungen
- **Kostenkontrolle & Reservierungen** â€“ PTUs kÃ¶nnen im Vorfeld gebucht oder bereitgestellt werden

Du kannst aber alternativ auch **Pay-as-you-go mit Shared Throughput** nutzen â€“ allerdings ist dann Deine Performance nicht garantiert (besonders bei hoher Last).
Durch solche Optionen kann man einen ChatBot den Anforderungen des Kunden anpassen ud skalieren.
Wird er Not zu 80% mit einer Vi!!!!!!!!!!!!!!!!!!!!!!!

## Was PTU NICHT ist:
| Falsch verstandene Bedeutung	| Richtig |
| â€Prompt Token Unitâ€œ	| âŒ Gibt es nicht |
| Token-Kontingent im Lizenzpaket	| âŒ Nicht direkt |
| Verbrauchsmessung pro API-Call	| âŒ Das lÃ¤uft Ã¼ber Token-Anzahl, nicht PTUs |

## ğŸ§  Fazit: PTU = Durchsatz, nicht Tokens
**PTUs sind keine MaÃŸeinheit fÃ¼r Tokenmengen**, sondern stehen fÃ¼r garantierte LeistungsfÃ¤higkeit (Throughput) Deiner Azure OpenAI Deployments.

**âœ… Fazit: Was solltest Du Dir merken?**
- Du bezahlst pro verbrauchtem Token, nicht pro Prompt.
- Es gibt Limits pro Minute (Tokens/Anfragen) â€“ die kannst Du aber skalieren.
- â€PTUsâ€œ sind eine Art Token-Paket â€“ aber (noch) nicht Ã¼berall relevant.
- Ein gutes KostenverstÃ¤ndnis hilft Dir, nicht bÃ¶se Ã¼berrascht zu werden â€“ und effizient zu skalieren.
