---
layout: post
title: Azure OpenAI GPT-Modelle - Vollst√§ndiger √úberblick ‚Äì leicht verst√§ndlich
tags: [CSP, Azure, GPT, Azure AI Foundry, Modelle]
---

Es gibt inzwischen so viele KI-Modelle √ºber Azure OpenAI ‚Äì da den √úberblick zu behalten, kann ganz sch√∂n herausfordernd sein. Aber keine Sorge, ich erkl√§re dir in diesem Beitrag alles Schritt f√ºr Schritt, verst√§ndlich und anschaulich. Von GPT-3.5 √ºber o-Serien, GPT-4-Reihe bis hin zu GPT-5, Audio- und Bildmodellen ‚Äì und sogar dem Modellrouter. Au√üerdem zeige ich dir, welche Modelle f√ºr welche Use Cases am besten geeignet sind.!<br>

Wenn du in Azure AI Foundry KI-Modelle ausrollen m√∂chtest, gibt es ein paar Dinge, die wichtig sind ‚Äì auch wenn du dich bei Foundry-Modellen wie GPT nicht um die eigentliche Infrastruktur k√ºmmern musst. Microsoft stellt diese Modelle als Managed Service bereit, das hei√üt: Skalierung, GPUs und Hochverf√ºgbarkeit laufen automatisch im Hintergrund. Deine Rolle verschiebt sich dadurch: Statt Compute-Kapazit√§ten zu planen, konzentrierst du dich auf die richtige Modellwahl, Kostenkontrolle und die Einbettung in deine Anwendungen. Achte darauf, von Anfang an sauber zwischen Test- und Produktionsumgebung zu trennen, um Transparenz und Kosten im Griff zu behalten. Sicherheit spielt ebenfalls eine zentrale Rolle: Richte Rollen und Berechtigungen sorgf√§ltig ein und denke an Datenschutz und Verschl√ºsselung, vor allem wenn sensible Daten verarbeitet werden. Ein weiterer Erfolgsfaktor ist Monitoring: Auch wenn du das Modell nicht selbst betreibst, solltest du Protokollierung, Auslastung und Antwortqualit√§t im Blick behalten ‚Äì so erkennst du fr√ºhzeitig, ob dein Setup angepasst werden muss. Und schlie√ülich ist es sinnvoll, die Kostenmodelle gut zu verstehen, da die Abrechnung meist nutzungsbasiert √ºber Tokens erfolgt. Kurz gesagt: Bei Foundry-Modellen musst du dich nicht um Hardware oder Compute k√ºmmern, aber daf√ºr umso mehr um Governance, Sicherheit, Monitoring und Kostenmanagement.<br><br>

Wenn du im Azure AI Foundry ein GPT-Modell von Microsoft nutzt, hast du mit den Rechenressourcen nichts direkt zu tun.

Die gesamte Infrastruktur ‚Äì GPUs, Skalierung, Updates, Verf√ºgbarkeit ‚Äì liegt bei Microsoft. F√ºr dich bleibt die Perspektive eine reine API-Nutzung:

<li>Du rufst das Modell √ºber einen Endpunkt auf.</li>
<li>Du zahlst nach Nutzungseinheiten (z. B. Tokens).</li>
<li>Du musst keine VM starten, keine GPU ausw√§hlen und auch kein Autoscaling konfigurieren.</li>

Deine Verantwortung verschiebt sich dadurch: Statt dich mit Hardware oder Compute zu besch√§ftigen, achtest du eher auf Themen wie Kostenkontrolle, Rate Limits, Zugriffssicherheit, Daten- und Prompt-Management sowie Governance.

üëâ Nur wenn du eigene Modelle trainierst oder hostest, kommst du wieder in die Welt der Rechenressourcen zur√ºck.<br><br>

## Welches Modell f√ºr welchen Use Case?

Die gro√üe St√§rke der Azure OpenAI Plattform liegt darin, dass du dir genau das Modell aussuchen kannst, das am besten zu deinem Projekt passt. Damit du nicht nur Tabellenwerte siehst, sondern auch verstehst, wof√ºr sich die einzelnen Varianten lohnen, habe ich die wichtigsten Anwendungsf√§lle hier ausf√ºhrlicher beschrieben:

| Use Case |	Modellgruppe |	Beschreibung & Vorteile |
| Standard-Textverarbeitung |	GPT-3.5, GPT-4 |	Ideal, wenn du klassische Chatbots, FAQ-Antworten oder Texterstellung brauchst. Diese Modelle sind zuverl√§ssig, laufen stabil und sind im Vergleich zu den neuesten Generationen g√ºnstiger. |
| Komplexe Analysen & Logik |	o-Series, GPT-4	| Wenn es um tiefere Analysen, datenbasierte Auswertungen oder komplexes Probleml√∂sen geht, bist du hier richtig. Diese Modelle k√∂nnen lange Kontexte verarbeiten und sind stark im ‚Äûlogischen Denken‚Äú. |
| Multimodale Aufgaben (Text & Bild) |	GPT-4o, GPT-4 Turbo |	Du willst Bilder beschreiben lassen oder Text mit Bildinhalten kombinieren? Diese Modelle verstehen und erzeugen multimodale Inhalte und sind perfekt f√ºr Szenarien wie Dokumentanalyse mit Bildanteilen oder kreative Content-Erstellung. |
| Realtime Sprachdialoge |	GPT-4o-realtime-preview |	Stelle dir vor, du sprichst mit einer KI wie mit einem echten Menschen. Diese Variante erm√∂glicht latenzarme Sprach-zu-Sprach-Kommunikation ‚Äì perfekt f√ºr Assistenten, Callcenter oder interaktive Sprachtools. |
| Transkription / TTS |	GPT-4o Audio-Modelle |	Wenn du Meetings transkribieren, Podcasts zusammenfassen oder Sprache in Text (und umgekehrt) verwandeln willst, bist du hier richtig. Die Audio-Modelle sind optimiert f√ºr Spracheingaben und -ausgaben. |
| Automatisiertes Modell-Routing |	model-router |	Du willst dich gar nicht mit Modellwahl besch√§ftigen? Der Router nimmt dir diese Entscheidung ab und leitet deine Anfrage automatisch an das am besten passende Modell weiter. Ideal f√ºr Systeme, die flexibel bleiben m√ºssen. |
| Tool-getriebene Antworten (Code etc.) |	computer-use-preview |	Dieses Modell ist f√ºr Szenarien gedacht, in denen die KI gezielt Tools steuert oder externe Systeme anbindet. Ein Beispiel: Code schreiben und gleichzeitig gleich testen lassen. |
| High-End Reasoning & gro√üe Kontexte |	GPT-5 (Standard) |	Hier bekommst du die volle Power: riesige Kontextfenster, logisches Denken, multimodale Verarbeitung. Geeignet f√ºr wissenschaftliche Analysen, komplexe Unternehmensprozesse oder Forschung. |
| Schnelle, ressourcenschonende KI |	GPT-5 mini / nano |	Nicht jede Aufgabe braucht die ‚Äûgro√üe Kanone‚Äú. Mini- und Nano-Modelle sind optimiert auf Geschwindigkeit und Kosten ‚Äì ideal f√ºr einfache Chatbots, Microservices oder Apps mit vielen gleichzeitigen Usern. |
| Chat-Agent mit Kontextmanagement  |	GPT-5 chat | Wenn du l√§ngere Gespr√§che f√ºhrst, in denen der Kontext nicht verloren gehen darf, spielt dieses Modell seine St√§rke aus. Ideal f√ºr Support-Chatbots oder pers√∂nliche Assistenten. |
| Lokale Nutzung / Offline |	gpt-oss-20B / 120B (Open-Weight) |	F√ºr alle, die ihre Daten nicht in die Cloud geben k√∂nnen oder wollen: Die Open-Weight-Modelle laufen lokal und bieten dir maximale Kontrolle ‚Äì mit dem Nachteil, dass du selbst die Infrastruktur stemmen musst. |<br>

üí° Tipp: Wenn du viele Anfragen gleichzeitig stellen m√∂chtest, ist GPT-5 Nano oder Mini aufgrund ihrer hohen TPM-Werte besonders geeignet. F√ºr kreative Aufgaben wie Storytelling oder Content Creation ist GPT-4.5 optimal, w√§hrend f√ºr komplexe logische Aufgaben GPT-5 Standard die beste Wahl ist.<br><br>

## Regionale Verf√ºgbarkeit der Modelle
<li><b>GPT-5 Modelle</b> (Standard, mini, nano, chat) sind aktuell in <b>East US 2</b> und <b>Sweden Central</b> verf√ºgbar. F√ºr GPT-5 ist eine Registrierung n√∂tig, die kleineren Varianten hingegen nicht</li>
<li>Die √§lteren Modelle <b>(GPT-4, o-Serien, GPT-4o etc.)</b> sind breit √ºber viele Regionen verf√ºgbar ‚Äì beispielweise auch in **Sweden Central, Germany West, East US, West US* und weiteren</li><br>

üí° Tipp: Sora ist aktuell nur eingeschr√§nkt verf√ºgbar. Wenn du also Videos einsetzen willst, solltest du vorher pr√ºfen, ob das Modell in deiner Region freigeschaltet ist.<br>

## Azure Speech Service vs. gpt-4o Realtime Preview
Der Azure Speech Service und gpt-4o Realtime Preview erf√ºllen unterschiedliche Rollen: Speech Service ist ein spezialisierter Sprachdienst f√ºr pr√§zise Transkription (ASR), nat√ºrlich klingende Text-to-Speech-Stimmen, √úbersetzungen und Speaker-Features wie Diarisierung. Er eignet sich vor allem, wenn es um saubere Transkripte, Anpassungen mit Fachvokabular, Custom Voices oder sogar On-Prem-Deployments mit strengen Datenschutzanforderungen geht und wird nach Audio-Stunden oder erzeugten Zeichen abgerechnet. gpt-4o Realtime hingegen ist ein multimodales Sprachmodell, das Audio direkt versteht und in Echtzeit generative Antworten als Text oder Sprache zur√ºckgibt ‚Äì also perfekt f√ºr interaktive Dialog-Systeme, Assistenten oder Voice Agents, bei denen es auf nat√ºrliche Konversationen ankommt. Technisch setzt es auf WebRTC/WebSockets f√ºr niedrige Latenz, hat in der Preview bestimmte Limits (z. B. ca. 100.000 Tokens pro Minute und 1.000 Requests pro Minute) und wird tokenbasiert abgerechnet. W√§hrend Speech Service f√ºr h√∂chste Transkriptionsqualit√§t und anpassbare Stimmen die bessere Wahl ist, punktet gpt-4o Realtime bei kontextreichen Gespr√§chen und generativer Intelligenz. In vielen Szenarien erg√§nzt sich beides: Speech Service liefert die robuste Sprachbasis, gpt-4o Realtime sorgt f√ºr die intelligente, konversationsf√§hige Ebene.<br><br>
Zu diesem Thema werden ich einen eigenes Blogbeitrag verfassen. Sei bespannt, welche Insides ich hier f√ºr dich hier habe.

## Fazit

Mit Azure AI Foundry erh√§ltst du Zugang zu einer breiten Palette von Modellen ‚Äì von klassischen Chatbots √ºber Bild-/Audio-KI bis hin zu leistungsf√§higen GPT-5-Varianten. √úberlege dir einfach:
<li><b>1.) Was ist dein Use Case?</b> (Text, Bild, Audio, Chat-Agent, Code etc.)</li>
<li><b>2.) Wie viel Leistung & Token-Kapazit√§t brauchst du?</b></li>
<li><b>3.) Wo wird das Modell gehostet?</b> (Regionale Verf√ºgbarkeit checken)</li>
<li><b>4.) Welche TPM- und Kostenbedingungen sind akzeptabel?</b></li>
Dann w√§hlst du das Modell, das am besten passt ‚Äì und nutzt es effizient, effizient und kostenbewusst.
