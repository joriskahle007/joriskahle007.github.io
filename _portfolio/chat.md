---
layout: post
title: Lizenz Audio Voice Bot - realisiert mit gpt4o Realtime + Fabric
img: "assets/img/portfolio/chat.png"
date: September 2014
tags: [ChatBot, Azure Open AI, GPT 4o Realtime, RAG ,Fabric]
---

![image]({{ page.img | relative_url }})

Wer sich mit den Lizenzmodellen von Microsoft auseinandersetzt, merkt ziemlich schnell: spannend klingt anders. Oft wirken die Regelwerke trocken, kompliziert und nicht immer eindeutig. Besonders dann, wenn verschiedene Lizenzmodelle ineinandergreifen, kann man sich leicht in Details verlieren. Unterschiedliche Auslegungen einzelner Passagen machen die Sache nicht leichter ‚Äì und ohne jahrelange Erfahrung oder direkten Draht zum Hersteller st√∂√üt man hier schnell an Grenzen. Klassische Modelle wie Open Value, Select, MPSA oder die bekannten Enterprise Agreements sind vielen zwar ein Begriff, wirken aber in Zeiten von Cloud und Flexibilit√§t schon fast wie Relikte. Microsoft selbst steuert daher klar in Richtung Zukunft: Das CSP-Modell soll langfristig das bunte Lizenz-Wirrwarr abl√∂sen.

Ein Sonderfall ist allerdings das SPLA-Modell (Service Provider Licensing Agreement). Hier √ºbernimmt nicht der Endkunde die Rolle des Lizenznehmers, sondern der Service Provider selbst ‚Äì mit dem besonderen Recht, diese Lizenzen an Endkunden weiterzuvermieten. Gerade in diesem Bereich fehlt es inzwischen an Experten, die die Feinheiten wirklich durchdringen. Und doch stehen zahlreiche Service Provider vor genau diesen lizenzrechtlichen Herausforderungen, bei denen fundiertes Fachwissen unerl√§sslich ist.

Genau hier setzte meine Idee an: Inspiriert durch ein Video von Pamela Fox im Microsoft Reactor wollte ich ausprobieren, ob sich die neuen M√∂glichkeiten von GPT-4o Realtime mit einer RAG-L√∂sung (Retrieval Augmented Generation) kombinieren lassen, um einen Sprach-basierten Lizenz-Bot zu entwickeln, der Service Providern direkt und zuverl√§ssig helfen kann. Statt das Rad neu zu erfinden, griff ich dabei auf ein vorhandenes Repository zur√ºck:üëâ <a href="https://github.com/Azure-Samples/aisearch-openai-rag-audio" target="_blank" rel="noopener">github.com/Azure-Samples/aisearch-openai-rag-audio</a>.

<img src="/assets/img/portfolio/aisearchgithub.jpg" alt="Azure AI Search RAG Audio" />

Das Architekturszenario ist denkbar spannend: √úber Azure AI Search wird der Datenbestand durchsucht, GPT-4o Realtime √ºbernimmt die Sprachschnittstelle, und als Datenplattform nutze ich Microsoft Fabric. Mit GitHub Codespaces habe ich die App per Script in meiner Azure Subscription deployed. Automatisch wurden die notwendigen Ressourcen erstellt: ein Container App Backend, ein Azure OpenAI Service mit GPT-4o Realtime, ein Search Service, ein Log Analytics Workspace, eine Container Apps Environment, eine Managed Identity sowie eine Container Registry.


## Das Architectur Diagramm sieht wie folgt aus:
<img src="/assets/img/portfolio/architecturediagram.jpg" alt="RAG Voice BOT - Architecture Diagram" />


Mit GitHub Codespaces habe ich die App per Script in meiner Azure Subscription deployed und gehofft, dass alles funktioniert. Als Datengrundlage legte ich zun√§chst einen Blob Storage an, lud die relevanten Lizenzdokumente hoch, passte das Frontend etwas an ‚Äì und schon schien der Bot betriebsbereit. Dachte ich zumindest.

## Folgende Services werden vom Script deployed:

<img src="/assets/img/portfolio/azureressource.jpg" alt="Azure AI Ressource" /><br><br>


Automatisch wurde vom System auch in AI Foundry das GPT-4o Realtime Modell deployd. Die Restlichen Modelle habe ich zu Testzwecken im Nachgang manuell ausgerollt.

<img src="/assets/img/portfolio/gptrealtime.jpg" alt="Azure AI Ressource" /><br>

Die Ern√ºchterung kam zun√§chst schnell: Die Antworten waren unpr√§zise, teilweise schlicht falsch. Denn im SPLA-Modell sind die Lizenzrechte klar in den sogenannten SPUR (Service Provider Use Rights) definiert, die Microsoft online bereitstellt. Ich hatte die Inhalte zwar in Word-Dateien kopiert und hochgeladen ‚Äì inklusive offizieller Vertragsdokumente ‚Äì aber das Modell fing trotzdem an zu halluzinieren und falsche Antworten als korrekt zu verkaufen. Damit wurde mir eines klar: Die Qualit√§t der Daten ist in solchen Szenarien absolut entscheidend. Also ging ich einen Schritt weiter und formulierte die Lizenzregeln in meinen eigenen Worten, so wie ich sie t√§glich Partnern erkl√§re. Je pr√§ziser ich wurde, desto verl√§sslicher antwortete der Bot.

Im n√§chsten Schritt verlagerte ich die Datenhaltung von Blob Storage auf Microsoft Fabric. Nicht nur, weil Microsoft selbst stark auf Fabric setzt, sondern auch, weil ich meine eigene Expertise dort ausbauen wollte. Ich richtete also einen Data Lake ein, lud die Dokumente hoch und konfigurierte den Azure AI Search Service so, dass nicht mehr Blob Storage, sondern der Data Lake indexiert wurde. Nach ein paar zus√§tzlichen Rechtevergaben in Fabric lief der Lizenzbot nun auf einer zukunftsweisenden Datenplattform ‚Äì und konnte nicht nur Antworten geben, sondern diese auch mit Quellen belegen.<br>


## Im DataLake wurden die Daten f√ºr den Indexder bereitgestellt:<br>

<img src="/assets/img/portfolio/datalake.jpg" alt="Azure - Fabric - Connector" /><br><br>




## Der Connector zu Fabric wurde eingerichtet:<br>

<img src="/assets/img/portfolio/connector.jpg" alt="Azure - Fabric - Connector" /><br><br>




## Und fertig war die finale L√∂sung:<br>
Das Spannende dabei ist noch, dass das Modell die Quelle von den Antworten gleich mit angibt und man hier nachlesen kann. 

<img src="/assets/img/portfolio/frontend.jpg" alt="GPT License Voice Audio Bot" /><br>


## Warum GPT-4o Realtime?

Der Einsatz von GPT-4o Realtime bietet im Vergleich zu klassischen Speech-to-Text- und Text-to-Speech-Services von Azure entscheidende Vorteile. W√§hrend die herk√∂mmlichen Dienste getrennt arbeiten und damit zwangsl√§ufig eine gewisse Latenz verursachen, ist GPT-4o Realtime multimodal trainiert und verarbeitet Sprache, Text und Audio in einem einzigen Modell. Das Ergebnis sind deutlich schnellere Reaktionszeiten, fl√ºssigere Dialoge und die F√§higkeit, sogar Tonalit√§t oder Emotionen im Sprachfluss zu ber√ºcksichtigen. Allerdings ist dieser Komfort auch mit h√∂heren Kosten verbunden und der Dienst ist aktuell nur in den USA und in Schweden verf√ºgbar ‚Äì daher musste ich in meiner Subscription auf die Region USA ausweichen.<br><br>

##Kosten der eingesetzten Dienste

Um ein Gef√ºhl f√ºr die Kosten zu bekommen, lohnt ein Blick auf die einzelnen Bausteine der L√∂sung:

- **Azure OpenAI (GPT-4o Realtime)**: Die Preise liegen bei rund **$44 pro Million Tokens** Input und **$88 pro Million Tokens Output**, mit deutlich g√ºnstigeren Raten bei gecachtem Input (ca. $2,75 pro Million Tokens). Ein Beispiel mit 1 Stunde Sprachdialog (etwa 360.000 Tokens) kommt schnell auf rund **$48 pro Nutzungseinheit**.

- **Azure AI Search**: Die Abrechnung erfolgt pro Such-Einheit (Search Unit). Im kleineren Basic-Tier liegt man bei etwa **75 ‚Ç¨ pro Monat**, f√ºr produktive Szenarien mit mehr Leistung sind es schnell **200‚Äì250 ‚Ç¨ pro Monat**.

- **Azure Container Apps**: Hier bezahlt man pro vCPU- und RAM-Sekunde. Durch die M√∂glichkeit, Instanzen auf null zu skalieren, bleiben die Kosten oft niedrig. In meinem Test lagen die Aufw√§nde je nach Auslastung zwischen **5 ‚Ç¨ und 25 ‚Ç¨ im Monat**.

- **Azure Container Registry**: F√ºr die Standardnutzung fallen ca. **4‚Äì5 ‚Ç¨ pro Monat an**.

- **Azure Log Analytics Workspace**: Hier wird nach eingehenden Logs abgerechnet. F√ºr die ersten 5 GB pro Monat ist der Service kostenlos, danach liegt der Preis bei etwa **2 ‚Ç¨ pro GB**. In meinem Szenario summierte sich das auf wenige Euro.

- **Azure Container Apps Environment**: Die Umgebung selbst verursacht keine hohen Zusatzkosten ‚Äì sie wird √ºber die Ressourcennutzung der eigentlichen Container Apps abgedeckt.

- **Managed Identity**: F√ºr die Identit√§tsverwaltung entstehen keine direkten Zusatzkosten.<br><br>

In Summe l√§sst sich das Projekt mit unter **100 ‚Ç¨ pro Monat im Testbetrieb** realisieren, sofern die Nutzung moderat bleibt. Mit produktiver Auslastung (intensive Sprachdialoge, viele Anfragen an die AI Search, gro√üe Logmengen) k√∂nnen die Kosten aber schnell dreistellig werden, wobei der gr√∂√üte Kostenblock klar beim GPT-4o Realtime-Modell liegt.

## Fazit

Das Projekt zeigt eindrucksvoll, welches Potenzial in der Verbindung von GPT-4o Realtime mit Azure AI Search und Microsoft Fabric steckt. Was bislang nur mit gro√üem Aufwand in klassischen Service-Abteilungen m√∂glich war, l√§sst sich nun durch einen intelligenten, Sprach-basierten Lizenzbot in Echtzeit bereitstellen. Die Vorteile liegen auf der Hand: Der Bot ist rund um die Uhr verf√ºgbar, ben√∂tigt keine Pausen, wird niemals krank und reagiert stets zuverl√§ssig sowie freundlich ‚Äì selbst dann, wenn die Anfrage zum hundertsten Mal gestellt wird.

Dar√ºber hinaus liefert er in k√ºrzester Zeit pr√§zise und nachvollziehbare Antworten, verweist direkt auf die zugrunde liegenden Dokumente und erm√∂glicht so nicht nur Effizienzsteigerung, sondern auch Transparenz und Vertrauen. Service-Mitarbeitende, die bislang stundenlang Dokumente durchforsten oder interne R√ºckfragen stellen mussten, k√∂nnen entlastet werden und sich auf komplexere oder beratungsintensive F√§lle konzentrieren. F√ºr Unternehmen bedeutet dies nicht nur einen enormen Produktivit√§tsgewinn, sondern auch eine klare Kostenreduktion ‚Äì sowohl durch die Automatisierung von Standardanfragen als auch durch die M√∂glichkeit, Servicekapazit√§ten gezielt dort einzusetzen, wo sie wirklich ben√∂tigt werden.

Es handelt sich hierbei um eine absolut bahnbrechende Entwicklung, die √ºber den konkreten Anwendungsfall SPLA-Lizenzierung weit hinausgeht. Ob im Kundenservice, im technischen Support oder in internen Wissensabteilungen ‚Äì ein solcher Sprachbot l√§sst sich bei jedem Endkunden einsetzen und an die jeweiligen Inhalte anpassen. Der Mehrwert ist universell: schnelle Antworten, Verf√ºgbarkeit rund um die Uhr und eine gleichbleibend hohe Qualit√§t der Ausk√ºnfte.

Damit √∂ffnet diese L√∂sung die T√ºr in eine neue √Ñra des intelligenten Kunden- und Servicemanagements. Unternehmen, die fr√ºhzeitig auf solche Technologien setzen, k√∂nnen sich nicht nur von Wettbewerbern abheben, sondern auch nachhaltig ihre Kostenstruktur verbessern, die Kundenzufriedenheit steigern und die Qualit√§t der internen Prozesse auf ein neues Level heben. Wenn Ihr FRagen habt, kommt gerne auf mich zu.

