---
layout: post
title: Bereit für KI mit Azure? Diese 5 Voraussetzungen solltest Du vor dem Start beachten
tags: [AI, Voraussetzungen]
---

## Foundry Memory – warum KI endlich ein Gedächtnis bekommt

Ich werde oft gefragt, warum sich viele KI Systeme manchmal so anfühlen, als hätten sie Alzheimer. Man erklärt etwas ausführlich, baut gemeinsam Kontext auf und ein paar Minuten später ist alles wieder weg. Genau an dieser Stelle kommt Foundry Memory ins Spiel. Und ja, das ist eines der Themen, bei denen ich selbst gemerkt habe, wie viel sich gerade unter der Haube von moderner KI verändert.

Foundry Memory ist im Kern der Versuch, KI Systemen so etwas wie ein echtes Gedächtnis zu geben. Kein starres Prompt Konstrukt, kein Copy Paste von Kontext in jede Anfrage, sondern ein Mechanismus, der Informationen speichert, wiederfindet und sinnvoll nutzt. Und zwar genau dann, wenn sie gebraucht werden.<br><br>

## Warum klassischer Kontext nicht reicht

Wenn wir heute mit einem Sprachmodell arbeiten, passiert technisch gesehen Folgendes: Wir schicken bei jeder Anfrage einen Prompt. In diesem Prompt steht alles drin, was das Modell wissen soll. Hintergrund, Rolle, Daten, Regeln. Das Modell selbst merkt sich davon nichts. Nach der Antwort ist alles weg.

Das funktioniert für einfache Aufgaben erstaunlich gut. Aber sobald es komplexer wird, zum Beispiel bei längeren Unterhaltungen, Agenten oder produktiven Anwendungen, wird es schnell anstrengend. Man muss ständig Kontext mitschleppen. Das kostet Tokens, Geld und vor allem Nerven.

Foundry Memory setzt genau hier an. Es trennt Wissen vom Prompt. Informationen werden strukturiert abgelegt und später gezielt wieder abgerufen.<br><br>

## Was Foundry Memory technisch wirklich macht

Unter der Oberfläche besteht Foundry Memory aus mehreren Bausteinen, die sauber zusammenspielen.

Der erste Baustein ist die Speicherung. Informationen werden nicht einfach als Text abgelegt, sondern in einer Form, die semantische Bedeutung enthält. Dafür werden Embeddings genutzt. Ein Embedding ist vereinfacht gesagt eine mathematische Repräsentation von Bedeutung. Zwei Inhalte, die sich ähnlich sind, liegen im Zahlenraum nah beieinander.

Diese Embeddings landen in einem Vektorspeicher. Das kann zum Beispiel Azure AI Search oder ein anderer Vektor Store sein. Wichtig ist nicht das Produkt, sondern das Prinzip. Wissen wird nicht nach exakten Wörtern gesucht, sondern nach Bedeutung.

Der zweite Baustein ist das Abrufen. Wenn eine neue Anfrage kommt, wird auch diese Anfrage in ein Embedding umgewandelt. Dann wird geschaut, welche gespeicherten Informationen semantisch am besten passen. Genau diese Informationen werden dann als Kontext an das Sprachmodell übergeben.

Der dritte Baustein ist die Steuerung. Foundry Memory entscheidet nicht blind. Es gibt Regeln, Prioritäten, Zeitbezüge und manchmal auch Rollen. Nicht jede Information ist immer relevant. Manche Dinge gelten nur für einen Nutzer, andere global. Manche veralten.

Das Zusammenspiel sorgt dafür, dass das Modell sich anfühlt, als würde es sich erinnern. In Wahrheit erinnert es sich nicht selbst. Aber es bekommt genau die richtigen Informationen zur richtigen Zeit.<br><br>

## Ein konkretes Beispiel aus der Praxis

Stell dir einen internen KI Assistenten für ein Unternehmen vor. Dieser Assistent kennt Prozesse, Abkürzungen, Ansprechpartner und typische Probleme.

Ein Mitarbeiter schreibt:
Ich habe ein Problem mit meiner Reisekostenabrechnung.

Foundry Memory sucht nun nicht im gesamten Internet, sondern im Unternehmensgedächtnis. Es findet zum Beispiel:

Die Reisekostenrichtlinie wurde im März angepasst
Für Bahnfahrten gilt eine Sonderregel
Ansprechpartner ist Frau Müller aus der Buchhaltung

Diese Informationen werden dem Modell mitgegeben und die Antwort wirkt plötzlich kompetent, konsistent und unternehmensspezifisch. Ohne dass jemand all das in den Prompt schreiben musste.<br><br>

## Foundry Memory - Kindgerecht erklärt:

Stell dir vor, du hast einen Roboter Freund. Jeden Tag erzählst du ihm Dinge. Dein Lieblingsessen ist Pizza. Dein Hund heißt Bello. Du magst Mathe nicht so gern.

Wenn der Roboter kein Gedächtnis hat, musst du ihm das jeden Tag neu erzählen. Das ist wie ein Freund, der dich jeden Morgen fragt, wie du heißt.

Foundry Memory ist wie ein Notizbuch für den Roboter. Jedes Mal, wenn du ihm etwas Wichtiges erzählst, schreibt er es auf. Wenn du ihn später fragst, was wir heute essen sollen, schaut er in sein Notizbuch und sagt Pizza, weil du das magst.

Der Roboter denkt nicht selbst nach wie ein Mensch. Aber er weiß, wo er nachschauen muss. Und das fühlt sich für dich genauso an wie echtes Erinnern.<br><br>

## Warum das so ein großer Schritt ist

Foundry Memory verändert die Art, wie wir KI Anwendungen bauen. Wir müssen nicht mehr alles in einen Prompt pressen. Wir können Wissen wachsen lassen. Wir können Agenten bauen, die über Wochen oder Monate sinnvoll arbeiten. Wir können Systeme schaffen, die sich an Nutzer anpassen, ohne jedes Mal neu trainiert zu werden.

Vor allem wird KI dadurch viel natürlicher. Gespräche wirken flüssiger. Antworten sind konsistenter. Und man merkt schnell, ob ein System Memory nutzt oder nicht.<br><br>

## Fazit

Foundry Memory ist kein kleines Feature. Es ist eine grundlegende Architekturentscheidung. Statt KI als kurzlebigen Textgenerator zu sehen, behandeln wir sie wie ein System mit Kontext, Wissen und Struktur.

Für mich ist das einer der wichtigsten Bausteine auf dem Weg zu wirklich hilfreichen KI Anwendungen. Nicht weil die Modelle schlauer werden, sondern weil wir endlich gelernt haben, ihnen ein brauchbares Gedächtnis zu geben.

Und ganz ehrlich: Einen Freund, der sich an mich erinnert, mag ich deutlich lieber als einen, der mich jeden Tag neu kennenlernen muss.
