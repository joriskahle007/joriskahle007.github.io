---
layout: post
title: Grundwissen - GPT, Token, PTUs & Prompts â€“ was Du verstehen solltest, bevor Du loslegst
tags: [GPT, Tokens, PTU, Prompt. LLM. Azure Open AI]
---

Bevor Du Dich in Azure AI Foundry, Azure OpenAI oder generell in generative KI stÃ¼rzt, ist es hilfreich, wenn Du ein paar grundlegende Begriffe verstehst. Viele davon begegnen Dir stÃ¤ndig â€“ z.â€¯B. in der Kostenberechnung oder beim Umgang mit Modellen wie GPT-4.

Hier kommt Dein Mini-Crashkurs.

## ğŸ“Œ Was ist GPT Ã¼berhaupt?
**GPT** steht fÃ¼r **Generative Pre-trained Transformer**. Es ist ein Sprachmodell, das:

- mit riesigen Mengen an Text vortrainiert wurde
- Sprache versteht und erzeugt (Text, Code, E-Mails, Zusammenfassungen etc.)
- mit sog. *Prompts* gesteuert wird â€“ also Texteingaben, mit denen Du dem Modell sagst, was es tun soll

Modelle wie **GPT-4**, **GPT-3.5**, oder **GPT-4 Turbo** sind Varianten dieses Prinzips â€“ jede Version ist leistungsfÃ¤higer, schneller oder gÃ¼nstiger.

## ğŸ§¾ Was ist ein Prompt?
Ein **Prompt** ist einfach gesagt **Dein Befehl an das Modell.**

Beispiele fÃ¼r Prompts:
- â€Fasse diesen Text in drei SÃ¤tzen zusammen.â€œ
- â€Schreibe eine Einladung fÃ¼r ein Sommerfest.â€œ
- â€Welche Risiken birgt generative KI in der Medizin?â€œ

Je besser Dein Prompt, desto prÃ¤ziser die Antwort â€“ das nennt man auch **Prompt Engineering.**

## ğŸ’³ Was sind Tokens und warum sind sie wichtig?
Ein **Token** ist ein Teil eines Wortes â€“ nicht immer ein ganzes Wort!
Token ist aber nicht gleich Toiken

| Beispiel | Wort | Token(s) |
| â€Computerâ€œ |	1 Wort |	1 Token |
| â€Unvorstellbarâ€œ |	1 Wort |	2 Tokens (â€Un-â€œ, â€vorstellbarâ€œ) |
| â€Hello, world!â€œ |	2 WÃ¶rter |	4 Tokens (Hello, ,, space, world!) |

Tokens sind deshalb wichtig, weil GPT-Modelle nach Tokens abgerechnet werden â€“ nicht nach WÃ¶rtern oder Prompts.

Beispiel:

- Du schreibst eine Eingabe mit 100 Tokens.
- GPT erzeugt eine Antwort mit 300 Tokens.
- Abgerechnet werden also 400 Tokens.

## ğŸ§© Wie funktioniert die Abrechnung in Azure OpenAI?
Wenn Du GPT Ã¼ber **Azure OpenAI** nutzt (auch Ã¼ber Foundry eingebunden), hast Du diese Abrechnungsgrundlagen:

## ğŸ”¢ Kosten nach Modell und Tokens
Du zahlst pro **1.000 Tokens**, abhÃ¤ngig vom Modell:

| Modell |	Prompt (Input) |	Completion (Output) |	Beispiel |
| GPT-4 Turbo |	ca. $0.01	| ca. $0.03	| pro 1.000 Tokens |
| GPT-3.5	| gÃ¼nstiger	| gÃ¼nstiger	| < $0.001 pro 1.000 Tokens |

Die **Preise kÃ¶nnen sich Ã¤ndern**, darum lohnt sich ein Blick auf <a https://azure.microsoft.com/de-de/pricing/details/cognitive-services/openai-service/>Microsofts Preisseite fÃ¼r Azure OpenAI</a>.

## â±ï¸ Was bedeutet Tokens per Minute (TPM)?
In Azure hast Du zusÃ¤tzlich **Rate Limits:**

- **Tokens per Minute (TPM)**: Wie viele Tokens Du pro Minute senden darfst.
- **Requests per Minute (RPM)**: Wie viele Anfragen Du pro Minute stellen darfst.

Wenn Du z.â€¯B. 240.000 TPM hast, kannst Du:

- 6 Anfragen mit je 40.000 Tokens
- oder 24 Anfragen mit je 10.000 Tokens
- â€¦ pro Minute senden

Diese Limits skalieren je nach deinem **Nutzungskontingent**, und Du kannst bei Microsoft **erhÃ¶hte Quoten beantragen**, wenn Du mehr brauchst.

## ğŸ“¦ Was ist eine Provisioned Throughput Unit (PTU)?
Eine **PTU** ist eine **Abrechnungseinheit in Azure OpenAI**, die Dir eine bestimmte Menge an RechenkapazitÃ¤t fÃ¼r GPT-Modelle zusichert â€“ Ã¤hnlich wie bei einer reservierten Bandbreite.

**Eine PTU bestimmt:**
- Wie viele **Token pro Minute (TPM)** Du verarbeiten kannst
- Welche **Modelle** (GPT-3.5, GPT-4, GPT-4 Turbo etc.) Du wie performant ansprechen kannst
- Wie hoch **verfÃ¼gbar** Deine Ressourcen sind

## ğŸ§® Was bekommst Du pro PTU?
Microsoft gibt typischerweise an:

- z.â€¯B. **1 PTU GPT-4 Turbo** = ~20 Requests/Minute mit je 8.000 Tokens (konkrete Werte kÃ¶nnen variieren)
- PTUs gelten **modellabhÃ¤ngig** â€“ d.â€¯h. GPT-3.5 hat gÃ¼nstigere, kleinere PTUs als GPT-4 Turbo
- Du kannst **mehrere PTUs buchen**, um KapazitÃ¤t zu skalieren

Diese PTUs gelten **pro Region und Deployment**, also z.â€¯B. â€West Europe â€“ GPT-4 Turbo â€“ 2 PTUsâ€œ.

## ğŸ’¡ Warum gibt es PTUs Ã¼berhaupt?
Microsoft bietet mit PTUs:

- **Planbare Leistung** â€“ Du bekommst zugesicherte KapazitÃ¤t, unabhÃ¤ngig von Auslastung
- **VerlÃ¤ssliche API-Nutzung** â€“ wichtig fÃ¼r produktive Anwendungen
- **Kostenkontrolle & Reservierungen** â€“ PTUs kÃ¶nnen im Vorfeld gebucht oder bereitgestellt werden

## âš–ï¸ Kombination von PTU & Pay-as-you-go â€“ das Beste aus zwei Welten
Azure OpenAI erlaubt Dir, **Provisioned Throughput (PTU)** und **Pay-as-you-go** nebeneinander zu nutzen, um Kosten und Performance dynamisch zu balancieren.
Gerade bei Lastspitzen kann der Weg Ã¼ber PTU sich auszahlen.

## ğŸ§© Wie funktioniert das?
Du kannst:

- **PTUs reservieren** fÃ¼r feste oder planbare Nutzung (z.â€¯B. werktags 9â€“17 Uhr, hohe Last)
- **Pay-as-you-go** nutzen, wenn Du keine PTUs brauchst oder zusÃ¤tzliche KapazitÃ¤t abfangen willst (z.â€¯B. nachts, am Wochenende, bei unregelmÃ¤ÃŸigen Peaks)

Dabei:

- werden Anfragen **zuerst Ã¼ber Provisioned Deployments** (mit PTUs) geleitet
- sobald diese an ihr **Limit stoÃŸen**, springt das **Shared Throughput Modell (pay-as-you-go)** ein â€“ falls verfÃ¼gbar und konfiguriert

## ğŸ’¡ Praktischer Einsatz:
| Zeitraum |	Strategie	Warum? |
| Montag â€“ Freitag, 8â€“18 Uhr |	PTUs aktiv nutzen	| Planbare Auslastung, garantierter Durchsatz |
| Nachts / Wochenende	| Pay-as-you-go	| Geringe Last, kein Bedarf an garantierter Performance |
| Bei Kampagnen oder Launches	| ZusÃ¤tzliche PTUs kurzfristig bereitstellen |	Skalierbar und stabil |
| Bei unsicherem Traffic |	Kombination aus beidem |	FlexibilitÃ¤t + Kostenoptimierung |

## âš ï¸ Fazit: PTU = Durchsatz, nicht Tokens
- **PTUs sind exklusiv**, Du bekommst garantierten Durchsatz â€“ aber zahlst auch, wenn Du sie nicht nutzt.
- **Pay-as-you-go ist flexibel**, aber unter UmstÃ¤nden gedrosselt, wenn die KapazitÃ¤t in Deiner Region begrenzt ist.
- **Azure Monitoring & Alerts** helfen Dir, zu erkennen, wann welche Route Ã¼berlastet ist â€“ damit Du ggf. nachsteuern kannst.

**ğŸ¯ Fazit: Was solltest Du Dir merken?**
- Tokenverbrauch = Input + Output, und Token â‰  Wort!
- -PTUs sichern Durchsatz, nicht Tokens an sich
- TPM & RPM sind Limitierungen, die durch PTUs beeinflusst werden
- Jedes Modell hat eigene Grenzen & Kosten â€“ GPT-4 â‰  GPT-3.5
- Du bezahlst pro verbrauchtem Token, nicht pro Prompt.
- Es gibt Limits pro Minute (Tokens/Anfragen) â€“ die kannst Du aber skalieren.
- â€PTUsâ€œ sind eine Art Token-Paket â€“ aber (noch) nicht Ã¼berall relevant.
- Ein gutes KostenverstÃ¤ndnis hilft Dir, nicht bÃ¶se Ã¼berrascht zu werden â€“ und effizient zu skalieren.

**Wenn Du planbare Kernzeiten hast, nutze PTUs fÃ¼r Performance und Kontrolle â€“ und ergÃ¤nze sie mit Pay-as-you-go fÃ¼r spontane oder niedrigpriorisierte Nutzung.
Das spart Geld, ohne auf ZuverlÃ¤ssigkeit zu verzichten.**
